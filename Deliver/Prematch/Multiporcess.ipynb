{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "''' LIBRARIES '''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "\n",
    "\n",
    "import re\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from sympy import symbols, Eq, solve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigators will be visible if `headless = False` , if you want to change it, change it's value to `True`.\n",
    "If one of the navigators stop working correctly, just close it and run again its code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Navigator ADMIRAL PREMATCH'''\n",
    "url_adm = 'https://admiralbet.rs/sport-prematch?sport=Fudbal'\n",
    "\n",
    "''' mike'''\n",
    "#chromeOptions = Options()\n",
    "#chromeOptions.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "#s= Service('/usr/local/bin/chromedriver')\n",
    "#adm = webdriver.Chrome(service=s, options=chromeOptions)\n",
    "''' ale'''\n",
    "options = Options()\n",
    "adm = webdriver.Chrome(r'C:\\Users\\KNL\\Desktop\\Ale\\Upwork\\Scraping_bets\\chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "adm.get(url_adm)\n",
    "adm.maximize_window()\n",
    "cookie = WebDriverWait(adm, 3).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"cookieContainer\"]/div[3]/a/span')))\n",
    "try:\n",
    "    cookie.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "adm.switch_to.frame(adm.find_element(By.XPATH, '//*[@id=\"sportIframe\"]'))\n",
    "\n",
    "day = WebDriverWait(adm, 4).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.time-option:nth-of-type(5)')))\n",
    "#day.click()\n",
    "\n",
    "adm.execute_script(\"document.body.style.zoom='90%'\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SOCCERBET NAVIGATOR '''\n",
    "url_soc = 'https://soccerbet.rs/#kladjenje'\n",
    "\n",
    "'''mike'''\n",
    "#chromeOptions = Options()\n",
    "#chromeOptions.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "#s= Service('/usr/local/bin/chromedriver')\n",
    "#soc = webdriver.Chrome(service=s, options=chromeOptions)\n",
    "\n",
    "''' ale'''\n",
    "options = Options()\n",
    "soc = webdriver.Chrome(r'C:\\Users\\KNL\\Desktop\\Ale\\Upwork\\Scraping_bets\\chromedriver.exe', options=options)\n",
    "\n",
    "soc.get(url_soc)\n",
    "soc.maximize_window()\n",
    "cancel = soc.find_element(By.XPATH, '//*[@id=\"promotionPopupModal\"]/div/div/div/div/input')\n",
    "cancel.click()\n",
    "day = WebDriverWait(soc, 4).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"home\"]/div[1]/div[1]/ul/li[3]/a/span[1]')))\n",
    "day.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Navigator Options               StarBET PREMATCH'''\n",
    "url_star = 'https://www.starbet.rs/Bet'\n",
    "''' mike '''\n",
    "#chromeOptions = Options()\n",
    "#chromeOptions.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "#s= Service('/usr/local/bin/chromedriver')\n",
    "#star = webdriver.Chrome(service=s, options=chromeOptions)\n",
    "\n",
    "''' ale '''\n",
    "options = Options()\n",
    "star = webdriver.Chrome(r'C:\\Users\\KNL\\Desktop\\Ale\\Upwork\\Scraping_bets\\chromedriver.exe', options=options)\n",
    "\n",
    "star.get(url_star)\n",
    "star.maximize_window()\n",
    "cancel = WebDriverWait(star, 4).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"zatvarac\"]')))\n",
    "cancel.click()\n",
    "checkmark_futbal = WebDriverWait(star, 2).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"tmpSportoviLigi\"]/div[2]/div[1]/h4/label/span')))\n",
    "checkmark_futbal.click()\n",
    "day = WebDriverWait(star, 3).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"tb459\"]/tbody/tr[1]/td[1]/span')))\n",
    "day.click()\n",
    "day.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Navigator MAXBET '''\n",
    "url_max = 'https://www.maxbet.rs/ibet-web-client/#/home#top'\n",
    "''' mike '''\n",
    "#chromeOptions = Options()\n",
    "#chromeOptions.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "#s= Service('/usr/local/bin/chromedriver')\n",
    "#maxb = webdriver.Chrome(service=s, options=chromeOptions)\n",
    "''' ale ''' \n",
    "options = Options()\n",
    "maxb = webdriver.Chrome(r'C:\\Users\\KNL\\Desktop\\Ale\\Upwork\\Scraping_bets\\chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "maxb.get(url_max)\n",
    "maxb.maximize_window()\n",
    "slider = maxb.find_element(By.XPATH, '//span[contains(@class, \"slider-handle\")]')\n",
    "ActionChains(maxb).drag_and_drop_by_offset(slider, -80,0).perform()\n",
    "#fudbal  = maxb.find_element(By.XPATH, '//*[@id=\"topView\"]/div/div[2]/div[1]/div[2]/div[4]/div/div[1]/div[1]/div[2]/div[1]')\n",
    "time.sleep(2)\n",
    "fudbal = WebDriverWait(maxb, 4).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"topView\"]/div/div[2]/div[1]/div[2]/div[4]/div/div[1]/div[1]/div[2]/div[1]')))\n",
    "#fudbal.click()\n",
    "fudbal.click()\n",
    "time.sleep(1)\n",
    "\n",
    "election = WebDriverWait(maxb, 4).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"topView\"]/div/div[2]/div[1]/div[2]/div[4]/div/div[1]/div[2]/div[1]')))\n",
    "#election  = maxb.find_element(By.XPATH, '//*[@id=\"topView\"]/div/div[2]/div[1]/div[2]/div[4]/div/div[1]/div[2]/div[1]')\n",
    "election.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starbet_pre():\n",
    "    df_star = pd.DataFrame(columns=['teams', '1_star', 'X_star', '2_star', 'under_star', 'goals_star', 'over_star'])\n",
    "    for j in tqdm(range(80)):\n",
    "        for k in range(1,40):\n",
    "            try:\n",
    "                elemento = star.find_element(By.XPATH, f'/html/body/form/div[4]/div/div/div/div[2]/div[6]/table[{j}]/tbody/tr[{k}]').text.split('\\n')\n",
    "                teams = elemento[1].replace(':', '')\n",
    "\n",
    "                home = elemento[2][:14].split(' ')[0]\n",
    "                tie  = elemento[2][:14].split(' ')[1]\n",
    "                away = elemento[2][:14].split(' ')[2]\n",
    "\n",
    "                goals = 2.5\n",
    "                under = elemento[2][35:44].split(' ')[0]\n",
    "                over  = elemento[2][35:44].split(' ')[1]\n",
    "\n",
    "                if len(elemento) == 3 :\n",
    "                    under = elemento[2].split(' ')[7]\n",
    "                    over  = elemento[2].split(' ')[8]\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                df_star.loc[len(df_star.index)] = [teams, home, tie, away, under, goals, over]\n",
    "            except:\n",
    "                pass\n",
    "        #clear_output()\n",
    "        #porcentaje = (j+1)*10/8\n",
    "        #print(f'starbet {porcentaje}%')\n",
    "    df_star.drop_duplicates(inplace=True)\n",
    "    df_star = df_star[~df_star.teams.str.contains('Utakmica')]\n",
    "    df_star.to_csv('CSV\\df_star.csv')\n",
    "    \n",
    "    return df_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starbet_pre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soccer_pre(pages=6):    \n",
    "    df_soc = pd.DataFrame(columns=['teams', '1_soc', 'X_soc', '2_soc', 'under_soc', 'goals_soc', 'over_soc'])\n",
    "\n",
    "    for j in range(pages):\n",
    "\n",
    "        nex = WebDriverWait(soc, 3).until(EC.presence_of_element_located((By.XPATH, '//span[contains(@class, \"triangle-right\")]')))\n",
    "        for k in range(40):\n",
    "            try:\n",
    "                elemento = soc.find_element(By.XPATH, f'//*[@id=\"result-tables\"]/div[2]/div[2]/div/table/tbody/tr[{k}]').text.split('\\n')\n",
    "                teams = elemento[1][4:]\n",
    "                \n",
    "                home = elemento[2]\n",
    "                tie = elemento[3]\n",
    "                away = elemento[4]\n",
    "\n",
    "                under = elemento[5]\n",
    "                goals = 2.5\n",
    "                over = elemento[6]\n",
    "            \n",
    "                df_soc.loc[len(df_soc.index)] = [teams, home, tie, away, under, goals, over]\n",
    "            except:\n",
    "                pass\n",
    "        nex.click()\n",
    "    time.sleep(2)\n",
    "    first = WebDriverWait(soc, 3).until(EC.presence_of_element_located((By.XPATH, '//span[contains(@class, \"fast-backward\")]')))\n",
    "    first.click()\n",
    "    first.click()\n",
    "    #clear_output()\n",
    "    #print('soccer_pre done')\n",
    "    df_soc.drop_duplicates(inplace=True)\n",
    "    df_soc.to_csv('CSV\\df_soc.csv')\n",
    "    return df_soc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soccer_pre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def admiral_pre(pages=7):\n",
    "    df_adm = pd.DataFrame(columns=['teams', '1_adm', 'X_adm', '2_adm', 'under_adm', 'goals_adm', 'over_adm', 'j', 'k'])\n",
    "    try:\n",
    "        adm.switch_to.frame(adm.find_element(By.XPATH, '//*[@id=\"sportIframe\"]'))\n",
    "    except:\n",
    "        pass\n",
    "    ''' exploring and filling df'''\n",
    "    for j in range(pages):\n",
    "        for k in range(30):\n",
    "            try:\n",
    "                elemento = adm.find_element(By.XPATH, f'//*[@id=\"centerContent\"]/app-sport-tree-selection-container/div/app-events-group/section/section/div/app-event[{k}]').text.split('\\n')\n",
    "                teams = elemento[3]+' '+elemento[4]\n",
    "                home=elemento[5]\n",
    "                tie =elemento[6]\n",
    "                away=elemento[7]\n",
    "                under=elemento[8]\n",
    "                goals = elemento[9]\n",
    "                over=elemento[10]\n",
    "                df_adm.loc[len(df_adm.index)] = [teams, home, tie, away, under, goals, over, j, k]\n",
    "            except:\n",
    "                pass\n",
    "        ''' changing pages '''\n",
    "        try:\n",
    "            paginations = adm.find_elements(By.CSS_SELECTOR, 'ul.pagination.ng-star-inserted>li[class=\"page-item\"]')\n",
    "            for page in paginations:\n",
    "                if page.text == 'Sledeća':\n",
    "                    #print('click')\n",
    "                    page.click()\n",
    "                    time.sleep(5)\n",
    "        except:\n",
    "            pass\n",
    "    ''' going back to first page or refresh ''' \n",
    "    try:\n",
    "        first = WebDriverWait(adm, 4).until(EC.presence_of_element_located((By.XPATH, '//li[contains(@class, \"page-item ng-star-inserted\")][1]')))\n",
    "        first.click()\n",
    "    except:\n",
    "        adm.refresh()\n",
    "        pass\n",
    "    ''' filtering and loading'''\n",
    "    df_adm = df_adm[~df_adm.teams.str.contains(\" AB\")]\n",
    "    df_adm.drop_duplicates('teams', inplace=True)\n",
    "    df_adm.to_csv('CSV\\df_adm.csv')\n",
    "    #print('admiral_pre done')\n",
    "    return df_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_adm = admiral_pre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxbet_pre():\n",
    "    df_max = pd.DataFrame(columns=['teams', '1_max', 'X_max', '2_max', 'under_max', 'goals_max', 'over_max'])\n",
    "    for j in range(60):\n",
    "        for k in range(40):\n",
    "            try:\n",
    "                elemento = maxb.find_element(By.XPATH, f'/html/body/div[1]/div[5]/div/div[2]/div[2]/div/div/div/div[2]/div[{j}]/league-with-matches/div/div[{k}]').text.split('\\n')\n",
    "                teams = elemento[2].replace('-','')\n",
    "                #print(teams, f'   ||   len elemento: {len(elemento)}, j: {j}, k: {k} ')\n",
    "\n",
    "                if len(elemento)==11:\n",
    "                    home = elemento[3]\n",
    "                    tie = elemento[4]\n",
    "                    away = elemento[5]\n",
    "                    under = elemento[6]\n",
    "                    goals = 2.5\n",
    "                    over = elemento[7]\n",
    "\n",
    "                if len(elemento)==12:\n",
    "                    home = elemento[4]\n",
    "                    tie = elemento[5]\n",
    "                    away = elemento[6]\n",
    "                    under = elemento[7]\n",
    "                    goals = 2.5\n",
    "                    over = elemento[8]\n",
    "\n",
    "                df_max.loc[len(df_max.index)] = [teams, home, tie, away, under, goals, over]\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "        porcentaje=round((j+1)*10/6, 3)\n",
    "        #clear_output()\n",
    "        #print(f'maxbet {porcentaje}%')\n",
    "    df_max = df_max.sort_values('1_max', ascending=False).drop_duplicates('teams').sort_index()\n",
    "    df_max.to_csv('CSV\\df_max.csv')\n",
    "    return df_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_max = maxbet_pre()\n",
    "#df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    '''          STARBET / ADMIRALBET '''\n",
    "    try:\n",
    "        df_star, df_adm = pd.read_csv('CSV\\df_star.csv') , pd.read_csv('CSV\\df_adm.csv')\n",
    "        teams_star = df_star.teams.tolist()\n",
    "\n",
    "        df_adm[['teams_matched', 'score']] = df_adm.teams.apply(lambda x:process.extractOne(x, teams_star, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_adm = df_adm[df_adm.score>60]\n",
    "\n",
    "        df_star_adm = pd.merge(df_adm, df_star, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_star_adm.drop_duplicates('teams_x',inplace=True)\n",
    "        df_star_adm.to_csv('CSV\\TwoWay\\PRE_star_adm.csv')\n",
    "    except:\n",
    "        print('Something went wrong. CHECK: ADMIRAL or STARBET PAGES')\n",
    "        pass\n",
    "\n",
    "    '''          ADMIRALBET / SOCCERBET ''' \n",
    "    try:\n",
    "        df_adm, df_soc = pd.read_csv('CSV\\df_adm.csv'), pd.read_csv('CSV\\df_soc.csv')\n",
    "\n",
    "        teams_adm = df_adm.teams.tolist()\n",
    "        teams_soc = df_soc.teams.tolist()\n",
    "\n",
    "        df_soc[['teams_matched', 'score']] = df_soc.teams.apply(lambda x: process.extractOne(x, teams_adm, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc = df_soc[df_soc.score>65]\n",
    "\n",
    "        df_soc_adm = pd.merge(df_soc, df_adm, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_soc_adm.drop_duplicates('teams_x',inplace=True)\n",
    "        df_soc_adm.to_csv('CSV\\TwoWay\\PRE_soc_adm.csv')\n",
    "    except:\n",
    "        print('Something went wrong. CHECK: ADMIRAL or SOCCERBET PAGES')\n",
    "        pass\n",
    "    '''         STARBET / SOCCERBET ''' \n",
    "\n",
    "    try:\n",
    "        df_star, df_soc = pd.read_csv('CSV\\df_star.csv'), pd.read_csv('CSV\\df_soc.csv')\n",
    "\n",
    "        teams_star = df_star.teams.tolist()\n",
    "        teams_soc = df_soc.teams.tolist()\n",
    "\n",
    "        df_soc[['teams_matched', 'score']] = df_soc.teams.apply(lambda x: process.extractOne(x, teams_star, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc = df_soc[df_soc.score>65]\n",
    "\n",
    "        df_soc_star = pd.merge(df_soc, df_star, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_soc_star.drop_duplicates('teams_x',inplace=True)\n",
    "        df_soc_star.to_csv('CSV\\TwoWay\\PRE_soc_star.csv') \n",
    "    except:\n",
    "        print('Something went wrong. CHECK: STARBET or SOCCERBET PAGES')\n",
    "        pass\n",
    "\n",
    "    '''          MAXBET / SOCCERBET '''\n",
    "    try:\n",
    "        df_soc, df_max = pd.read_csv('CSV\\df_soc.csv'), pd.read_csv('CSV\\df_max.csv')\n",
    "\n",
    "        teams_soc = df_soc.teams.tolist()\n",
    "        teams_max = df_max.teams.tolist()\n",
    "\n",
    "        df_soc[['teams_matched', 'score']] = df_soc.teams.apply(lambda x:process.extractOne(x, teams_max, scorer= fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc = df_soc[df_soc.score>65]\n",
    "\n",
    "        df_soc_max = pd.merge(df_soc, df_max, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_soc_max.drop_duplicates('teams_x',inplace=True)\n",
    "        df_soc_max.to_csv('CSV\\TwoWay\\PRE_soc_max.csv')\n",
    "    except:\n",
    "        print('Something went wrong. CHECK: MAXBET or SOCCERBET PAGES')\n",
    "\n",
    "\n",
    "    '''          MAXBET / ADMIRAL ''' \n",
    "    try:\n",
    "        df_adm, df_max = pd.read_csv('CSV\\df_adm.csv'), pd.read_csv('CSV\\df_max.csv')\n",
    "\n",
    "        teams_adm = df_adm.teams.tolist()\n",
    "        teams_max = df_max.teams.tolist()\n",
    "\n",
    "        df_adm[['teams_matched', 'score']] = df_adm.teams.apply(lambda x:process.extractOne(x, teams_max, scorer= fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_adm = df_adm[df_adm.score>65]\n",
    "\n",
    "        df_adm_max = pd.merge(df_adm, df_max, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_adm_max.drop_duplicates('teams_x',inplace=True)\n",
    "        df_adm_max.to_csv('CSV\\TwoWay\\PRE_adm_max.csv')\n",
    "    except:\n",
    "        print('Something went wrong. CHECK: ADMIRAL or MAXBET PAGES')\n",
    "    \n",
    "    '''          MAXBET / STARBET ''' \n",
    "    try:\n",
    "        df_max, df_star =  pd.read_csv('CSV\\df_max.csv'), pd.read_csv('CSV\\df_star.csv')\n",
    "        \n",
    "        teams_star = df_star.teams.tolist()\n",
    "\n",
    "        df_max[['teams_matched', 'score']] = df_max.teams.apply(lambda x:process.extractOne(x, teams_star, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_max = df_max[df_max.score>65]\n",
    "\n",
    "        df_max_star = pd.merge(df_max,df_star, left_on='teams_matched', right_on='teams', how='left')\n",
    "        df_max_star.drop_duplicates('teams_x',inplace=True)\n",
    "        df_max_star.to_csv('CSV\\TwoWay\\PRE_max_star.csv')\n",
    "    except:\n",
    "        print('Something went wrong. CHECK: MAXBET or STARBET PAGES')\n",
    "\n",
    "\n",
    "    '''                                     3WAY MERGES''' \n",
    "\n",
    "\n",
    "    ''' AD / ST / SC '''\n",
    "    # loading data\n",
    "    try:\n",
    "        df_soc_adm = pd.read_csv('CSV\\TwoWay\\PRE_soc_adm.csv')\n",
    "        df_soc_adm.drop(columns=['Unnamed: 0', 'Unnamed: 0_x','Unnamed: 0_y'], inplace=True)\n",
    "        df_star = pd.read_csv('CSV\\df_star.csv')\n",
    "        #Start Merging process\n",
    "        teams_star = df_star.teams.tolist()\n",
    "        df_soc_adm[['teams_matched2', 'score']] = df_soc_adm.teams_matched.apply(lambda x:process.extractOne(x, teams_star, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc_adm = df_soc_adm[df_soc_adm.score>60] #This drops all the teams names that don't match among sites\n",
    "        #The last merging process\n",
    "        df_soc_adm_star = pd.merge(df_soc_adm, df_star, left_on='teams_matched2', right_on='teams', how='left')\n",
    "        df_soc_adm_star.drop_duplicates('teams', inplace=True)\n",
    "        df_soc_adm_star.to_csv('CSV\\ThreeWay\\Pre_soc_adm_star.csv')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    ''' AD / SC / MAX '''\n",
    "    # loading data\n",
    "    try:\n",
    "        df_soc_adm = pd.read_csv('CSV\\TwoWay\\PRE_soc_adm.csv')\n",
    "        df_soc_adm.drop(columns=['Unnamed: 0', 'Unnamed: 0_x','Unnamed: 0_y','score' ], inplace=True)\n",
    "        df_max = pd.read_csv('CSV\\df_max.csv')\n",
    "        #Start Merging process\n",
    "        teams_max = df_max.teams.tolist()\n",
    "        df_soc_adm[['teams_matched2', 'score']] = df_soc_adm.teams_matched.apply(lambda x:process.extractOne(x, teams_max, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc_adm = df_soc_adm[df_soc_adm.score>65] #This drops all the teams names that don't match among sites\n",
    "        #The last merging process\n",
    "        df_soc_adm_max = pd.merge(df_soc_adm, df_max, left_on='teams_matched2', right_on='teams', how='left')\n",
    "        df_soc_adm_max.drop_duplicates('teams', inplace=True)\n",
    "        df_soc_adm_max.to_csv('CSV\\ThreeWay\\Pre_soc_adm_max.csv')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    ''' SC / ST / MAX '''\n",
    "    try:\n",
    "        df_soc_star = pd.read_csv('CSV\\TwoWay\\PRE_soc_star.csv')\n",
    "        df_soc_star.drop(columns=['Unnamed: 0', 'Unnamed: 0_x','Unnamed: 0_y', 'score' ], inplace=True)\n",
    "\n",
    "        teams_max = df_max.teams.tolist()\n",
    "        df_soc_star[['teams_matched2', 'score']] = df_soc_star.teams_matched.apply(lambda x:process.extractOne(x, teams_max, scorer=fuzz.token_sort_ratio)).apply(pd.Series)\n",
    "        df_soc_star = df_soc_star[df_soc_star.score>65] #This drops all the teams names that don't match among sites\n",
    "        #The last merging process\n",
    "        df_soc_star_max = pd.merge(df_soc_star, df_max, left_on='teams_matched2', right_on='teams', how='left')\n",
    "        df_soc_star_max.drop_duplicates('teams', inplace=True)\n",
    "        df_soc_star_max.to_csv('CSV\\ThreeWay\\Pre_soc_star_max.csv')\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function(minutos):\n",
    "    # TIME STUFF\n",
    "    target = pd.datetime.now() + pd.to_timedelta(minutos, unit='min')\n",
    "    target_minute = target.minute\n",
    "    target_hour = target.hour\n",
    "    now = pd.datetime.now()\n",
    "    now_minute = now.minute\n",
    "    now_hour = now.hour\n",
    "    i=0\n",
    "    #THREADS\n",
    "    \n",
    "    # Put everything to work\n",
    "\n",
    "    while target>now:\n",
    "        clear_output()\n",
    "        \n",
    "\n",
    "        admiralbet = threading.Thread(target=admiral_pre)\n",
    "        soccerbet = threading.Thread(target=soccer_pre)\n",
    "        starbet = threading.Thread(target=starbet_pre)\n",
    "        maxbet = threading.Thread(target=maxbet_pre)\n",
    "\n",
    "\n",
    "        i+=1\n",
    "        print(f'Will work till: {target_hour}hs and {target_minute}mins')\n",
    "        print(f'Iteration number: {i}')\n",
    "\n",
    "        admiralbet.start()\n",
    "        soccerbet.start() \n",
    "        maxbet.start()\n",
    "        starbet.start()\n",
    "        print('-------')\n",
    "        print('Functions started')\n",
    "\n",
    "        admiralbet.join()\n",
    "        soccerbet.join()\n",
    "        maxbet.join()\n",
    "        starbet.join()\n",
    "        \n",
    "\n",
    "        print('Scrapers done')\n",
    "        print('-------')\n",
    "        print('Merging start...')\n",
    "        merge()\n",
    "        print('-------')\n",
    "        print('Merging finished! All csv files have been updated')\n",
    "        time.sleep(3)\n",
    "        now = pd.datetime.now()\n",
    "        now_minute = now.minute\n",
    "        now_hour = now.hour \n",
    "    \n",
    "    #print(f'iteration {i}/{tiempo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For __enable__/__disable__ some of the pages, you should go inside the `final_function(minutos):`(just above). Find the page you want to enable/disable and __ADD__ a ___#___ before `page`.start() __and__ `page`.join() you want to enable/disable. \n",
    "\n",
    "For example:\n",
    "You want to disable __MaxBET__ , so you go and find __maxbet.start()__ and __maxbet.join()__ and aggregate a # before them. Like: #maxbet.start() __and__ #maxbet.join(). \n",
    "\n",
    "You might want to do this in here with starbet because it is a bottleneck in this process, for a faster update of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMATCH Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `input` argument of this function goes for how many `minutes` you want the scraper to work. It can work indefinitely, but I recomend discrete periods of time, for example 60 minutes or so. \n",
    "\n",
    "The `output` of this function are all the csv(excel files) that are being saved continuosly while it's working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will work till: 22hs and 34mins\n",
      "Iteration number: 1\n",
      "-------\n",
      "Functions started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [01:02<01:36,  2.05s/it]"
     ]
    }
   ],
   "source": [
    "final_function(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
